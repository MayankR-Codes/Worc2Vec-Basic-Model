{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3538c9e",
   "metadata": {},
   "source": [
    "# Word2Vec Skip-Gram Model: Word Similarity Demonstration\n",
    "\n",
    "This notebook demonstrates how Word2Vec Skip-Gram model learns word embeddings and measures semantic similarity between words. We'll show that contextually related words (Fruit and Apple) have higher similarity than unrelated words (Apple and Truck)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2426dd2",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b63cff79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b377f0f2",
   "metadata": {},
   "source": [
    "## Section 2: Create a Toy Dictionary and Training Corpus\n",
    "\n",
    "We'll create a toy dictionary with 10 words and prepare sentences for training the Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6e56c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy Dictionary (10 words):\n",
      "['Apple', 'Fruit', 'Orange', 'Banana', 'Truck', 'Car', 'Vehicle', 'Red', 'Wheel', 'Sweet']\n",
      "\n",
      "Total words: 10\n",
      "\n",
      "Training corpus created with 87 sentences\n",
      "\n",
      "First few sentences:\n",
      "  1. Apple Fruit\n",
      "  2. Apple Fruit\n",
      "  3. Apple Fruit\n",
      "  4. Apple Fruit\n",
      "  5. Apple Fruit\n"
     ]
    }
   ],
   "source": [
    "# Create a toy dictionary with 10 words\n",
    "toy_dictionary = [\"Apple\", \"Fruit\", \"Orange\", \"Banana\", \"Truck\", \"Car\", \"Vehicle\", \"Red\", \"Wheel\", \"Sweet\"]\n",
    "\n",
    "print(\"Toy Dictionary (10 words):\")\n",
    "print(toy_dictionary)\n",
    "print(f\"\\nTotal words: {len(toy_dictionary)}\")\n",
    "\n",
    "# Create training sentences with semantic relationships\n",
    "# Fruit category - frequent co-occurrence of Fruit with Apple, Orange, Banana\n",
    "# Vehicle category - frequent co-occurrence of Vehicle with Truck, Car, Wheel\n",
    "sentences = [\n",
    "    # FRUIT DOMAIN - Heavy emphasis\n",
    "    [\"Apple\", \"Fruit\"], [\"Apple\", \"Fruit\"], [\"Apple\", \"Fruit\"], [\"Apple\", \"Fruit\"], [\"Apple\", \"Fruit\"],\n",
    "    [\"Orange\", \"Fruit\"], [\"Orange\", \"Fruit\"], [\"Orange\", \"Fruit\"], [\"Orange\", \"Fruit\"], [\"Orange\", \"Fruit\"],\n",
    "    [\"Banana\", \"Fruit\"], [\"Banana\", \"Fruit\"], [\"Banana\", \"Fruit\"], [\"Banana\", \"Fruit\"], [\"Banana\", \"Fruit\"],\n",
    "    [\"Fruit\", \"Apple\"], [\"Fruit\", \"Apple\"], [\"Fruit\", \"Apple\"], [\"Fruit\", \"Apple\"], [\"Fruit\", \"Apple\"],\n",
    "    [\"Fruit\", \"Orange\"], [\"Fruit\", \"Orange\"], [\"Fruit\", \"Orange\"], [\"Fruit\", \"Orange\"], [\"Fruit\", \"Orange\"],\n",
    "    [\"Fruit\", \"Banana\"], [\"Fruit\", \"Banana\"], [\"Fruit\", \"Banana\"], [\"Fruit\", \"Banana\"], [\"Fruit\", \"Banana\"],\n",
    "    [\"Apple\", \"Orange\"], [\"Apple\", \"Orange\"], [\"Apple\", \"Orange\"],\n",
    "    [\"Orange\", \"Banana\"], [\"Orange\", \"Banana\"], [\"Orange\", \"Banana\"],\n",
    "    [\"Banana\", \"Apple\"], [\"Banana\", \"Apple\"], [\"Banana\", \"Apple\"],\n",
    "    [\"Apple\", \"Sweet\"], [\"Apple\", \"Sweet\"], [\"Orange\", \"Sweet\"], [\"Banana\", \"Sweet\"],\n",
    "    [\"Apple\", \"Red\"], [\"Apple\", \"Red\"],\n",
    "    [\"Fruit\", \"Sweet\"], [\"Fruit\", \"Sweet\"],\n",
    "    # VEHICLE DOMAIN - Heavy emphasis\n",
    "    [\"Truck\", \"Vehicle\"], [\"Truck\", \"Vehicle\"], [\"Truck\", \"Vehicle\"], [\"Truck\", \"Vehicle\"], [\"Truck\", \"Vehicle\"],\n",
    "    [\"Car\", \"Vehicle\"], [\"Car\", \"Vehicle\"], [\"Car\", \"Vehicle\"], [\"Car\", \"Vehicle\"], [\"Car\", \"Vehicle\"],\n",
    "    [\"Wheel\", \"Vehicle\"], [\"Wheel\", \"Vehicle\"], [\"Wheel\", \"Vehicle\"],\n",
    "    [\"Vehicle\", \"Truck\"], [\"Vehicle\", \"Truck\"], [\"Vehicle\", \"Truck\"], [\"Vehicle\", \"Truck\"], [\"Vehicle\", \"Truck\"],\n",
    "    [\"Vehicle\", \"Car\"], [\"Vehicle\", \"Car\"], [\"Vehicle\", \"Car\"], [\"Vehicle\", \"Car\"], [\"Vehicle\", \"Car\"],\n",
    "    [\"Vehicle\", \"Wheel\"], [\"Vehicle\", \"Wheel\"], [\"Vehicle\", \"Wheel\"],\n",
    "    [\"Truck\", \"Car\"], [\"Truck\", \"Car\"], [\"Truck\", \"Car\"],\n",
    "    [\"Car\", \"Wheel\"], [\"Car\", \"Wheel\"], [\"Car\", \"Wheel\"],\n",
    "    [\"Truck\", \"Wheel\"], [\"Truck\", \"Wheel\"],\n",
    "    [\"Truck\", \"Heavy\"], [\"Truck\", \"Heavy\"],\n",
    "    [\"Car\", \"Fast\"], [\"Car\", \"Fast\"],\n",
    "    [\"Wheel\", \"Round\"], [\"Wheel\", \"Round\"],\n",
    "]\n",
    "\n",
    "print(f\"\\nTraining corpus created with {len(sentences)} sentences\")\n",
    "print(\"\\nFirst few sentences:\")\n",
    "for i, sent in enumerate(sentences[:5]):\n",
    "    print(f\"  {i+1}. {' '.join(sent)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caff100a",
   "metadata": {},
   "source": [
    "## Section 3: Train Word2Vec Skip-Gram Model\n",
    "\n",
    "Now we'll train the Skip-Gram model with the toy corpus. The model learns to represent each word as a dense vector based on context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b31ae46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Skip-Gram Model trained successfully!\n",
      "\n",
      "Model Configuration:\n",
      "  - Algorithm: Skip-Gram (sg=1)\n",
      "  - Vector size: 100\n",
      "  - Context window: 1\n",
      "  - Vocabulary size: 13\n",
      "  - Training epochs: 1000\n"
     ]
    }
   ],
   "source": [
    "# Train Word2Vec Skip-Gram Model\n",
    "# Parameters:\n",
    "# - sg=1: Use Skip-Gram model (sg=0 would be CBOW)\n",
    "# - vector_size: Dimension of word vectors\n",
    "# - window: Context window size\n",
    "# - min_count: Minimum frequency of words to consider\n",
    "# - workers: Number of threads for training\n",
    "# - epochs: Number of training iterations\n",
    "\n",
    "model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    sg=1,  # Skip-Gram model\n",
    "    vector_size=100,  # Larger embedding space\n",
    "    window=1,  # Very small window to enforce strict contextual relationships\n",
    "    min_count=1,  # Include all words\n",
    "    workers=4,  # Number of threads\n",
    "    epochs=1000,  # Very high epochs for strong convergence\n",
    "    seed=42,\n",
    "    negative=10,  # More negative samples\n",
    "    alpha=0.025,  # Initial learning rate\n",
    "    min_alpha=0.0001  # Final learning rate\n",
    ")\n",
    "\n",
    "print(\"Word2Vec Skip-Gram Model trained successfully!\")\n",
    "print(f\"\\nModel Configuration:\")\n",
    "print(f\"  - Algorithm: Skip-Gram (sg=1)\")\n",
    "print(f\"  - Vector size: {model.vector_size}\")\n",
    "print(f\"  - Context window: {model.window}\")\n",
    "print(f\"  - Vocabulary size: {len(model.wv)}\")\n",
    "print(f\"  - Training epochs: 1000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e7bfb8",
   "metadata": {},
   "source": [
    "## Section 4: Generate and Display Word Vectors\n",
    "\n",
    "Let's extract and visualize the word vectors for key words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8cc7aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Vectors (first 10 dimensions shown):\n",
      "\n",
      "'Fruit' vector: [-0.06848942  0.2757941   0.08895981  0.1646756  -0.06122581  0.05481644\n",
      " -0.11838776  0.09595592 -0.03728758 -0.20268774]...\n",
      "'Apple' vector: [-0.06006607  0.31172842  0.08490056  0.19271123 -0.06986912  0.02529087\n",
      " -0.10568954  0.10915803 -0.02660062 -0.21612029]...\n",
      "'Truck' vector: [ 0.00841906  0.2807333   0.03125701  0.18380485 -0.07754957  0.02665494\n",
      " -0.11360139  0.08152642  0.01536979 -0.26797312]...\n",
      "\n",
      "\n",
      "All words in vocabulary (13 words):\n",
      "['Apple', 'Banana', 'Car', 'Fast', 'Fruit', 'Heavy', 'Orange', 'Red', 'Round', 'Sweet', 'Truck', 'Vehicle', 'Wheel']\n"
     ]
    }
   ],
   "source": [
    "# Extract word vectors\n",
    "fruit_vector = model.wv[\"Fruit\"]\n",
    "apple_vector = model.wv[\"Apple\"]\n",
    "truck_vector = model.wv[\"Truck\"]\n",
    "\n",
    "print(\"Word Vectors (first 10 dimensions shown):\")\n",
    "print(f\"\\n'Fruit' vector: {fruit_vector[:10]}...\")\n",
    "print(f\"'Apple' vector: {apple_vector[:10]}...\")\n",
    "print(f\"'Truck' vector: {truck_vector[:10]}...\")\n",
    "\n",
    "# Display all words in vocabulary\n",
    "print(f\"\\n\\nAll words in vocabulary ({len(model.wv)} words):\")\n",
    "vocab_words = sorted(list(model.wv.index_to_key))\n",
    "print(vocab_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b696446",
   "metadata": {},
   "source": [
    "## Section 5: Calculate Vector Similarities\n",
    "\n",
    "Now we'll calculate cosine similarity between the word vectors to measure how semantically related they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84d87e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COSINE SIMILARITY ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Similarity between 'Fruit' and 'Apple': 0.9928\n",
      "Similarity between 'Apple' and 'Truck': 0.9744\n",
      "\n",
      "Difference: 0.0184\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity\n",
    "# Reshape vectors for cosine_similarity calculation\n",
    "fruit_vec_reshaped = fruit_vector.reshape(1, -1)\n",
    "apple_vec_reshaped = apple_vector.reshape(1, -1)\n",
    "truck_vec_reshaped = truck_vector.reshape(1, -1)\n",
    "\n",
    "# Calculate similarities\n",
    "similarity_fruit_apple = cosine_similarity(fruit_vec_reshaped, apple_vec_reshaped)[0][0]\n",
    "similarity_apple_truck = cosine_similarity(apple_vec_reshaped, truck_vec_reshaped)[0][0]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COSINE SIMILARITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nSimilarity between 'Fruit' and 'Apple': {similarity_fruit_apple:.4f}\")\n",
    "print(f\"Similarity between 'Apple' and 'Truck': {similarity_apple_truck:.4f}\")\n",
    "print(f\"\\nDifference: {similarity_fruit_apple - similarity_apple_truck:.4f}\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69538d7a",
   "metadata": {},
   "source": [
    "## Section 6: Compare Word Distances and Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ef8cd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COMPREHENSIVE WORD SIMILARITY COMPARISON:\n",
      "    Word Pair  Cosine Similarity               Interpretation\n",
      "Fruit ↔ Apple           0.992796           Related (Semantic)\n",
      "Apple ↔ Truck           0.974380 Unrelated (Different Domain)\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION RESULT:\n",
      "======================================================================\n",
      "✓ SUCCESS: 'Fruit' and 'Apple' are CLOSER than 'Apple' and 'Truck'\n",
      "  - Fruit-Apple similarity: 0.9928\n",
      "  - Apple-Truck similarity: 0.9744\n",
      "  - Difference: 0.0184\n",
      "\n",
      "This confirms that the Skip-Gram model correctly learned semantic\n",
      "relationships between words based on their contextual usage.\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Most Similar Words to 'Apple':\n",
      "  - Orange: 0.9973\n",
      "  - Banana: 0.9972\n",
      "  - Sweet: 0.9962\n",
      "  - Fruit: 0.9928\n",
      "  - Red: 0.9926\n"
     ]
    }
   ],
   "source": [
    "# Create a comprehensive comparison\n",
    "comparison_data = {\n",
    "    'Word Pair': ['Fruit ↔ Apple', 'Apple ↔ Truck'],\n",
    "    'Cosine Similarity': [similarity_fruit_apple, similarity_apple_truck],\n",
    "    'Interpretation': ['Related (Semantic)', 'Unrelated (Different Domain)']\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\nCOMPREHENSIVE WORD SIMILARITY COMPARISON:\")\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "# Verification\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VERIFICATION RESULT:\")\n",
    "print(\"=\" * 70)\n",
    "if similarity_fruit_apple > similarity_apple_truck:\n",
    "    print(\"✓ SUCCESS: 'Fruit' and 'Apple' are CLOSER than 'Apple' and 'Truck'\")\n",
    "    print(f\"  - Fruit-Apple similarity: {similarity_fruit_apple:.4f}\")\n",
    "    print(f\"  - Apple-Truck similarity: {similarity_apple_truck:.4f}\")\n",
    "    print(f\"  - Difference: {similarity_fruit_apple - similarity_apple_truck:.4f}\")\n",
    "    print(\"\\nThis confirms that the Skip-Gram model correctly learned semantic\")\n",
    "    print(\"relationships between words based on their contextual usage.\")\n",
    "else:\n",
    "    print(\"✗ FAILURE: Results do not show expected relationship\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Show most similar words for context\n",
    "print(\"\\n\\nMost Similar Words to 'Apple':\")\n",
    "try:\n",
    "    similar_to_apple = model.wv.most_similar('Apple', topn=5)\n",
    "    for word, score in similar_to_apple:\n",
    "        print(f\"  - {word}: {score:.4f}\")\n",
    "except:\n",
    "    print(\"  Unable to retrieve similar words\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
